# Linear Regression from Scratch

This project presents a manual implementation of **Linear Regression** using only core Python libraries. The notebook trains a regression model on synthetically generated multi-feature data using **gradient descent**, providing a clear understanding of how linear models work internally.

 ğŸ“Œ Project Overview

Linear Regression is one of the most fundamental algorithms in supervised machine learning. In this project, we:
- Generate synthetic data with 3 input features and a known linear relationship
- Add random noise to simulate real-world data
- Manually implement gradient descent to train weights and bias
- Visualize the cost function over time

This notebook is educational and ideal for learners aiming to grasp how linear regression is computed without relying on external ML libraries like `scikit-learn`.

 ğŸ“ Repository Contents

| File                        | Description                                                 |
|-----------------------------|-------------------------------------------------------------|
| linear regression.ipynb   | Jupyter Notebook implementing multi-variable linear regression from scratch |


 ğŸ› ï¸ Technologies & Libraries

- `numpy` â€“ for linear algebra and numerical computations  
- `matplotlib` â€“ for data and cost function visualization  




