{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=2,          # Only 2 useful features for visualization\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=0.8,         # Low separation makes it harder\n",
    "    flip_y=0.1,            # Add noise (10% label flipping)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color=\"red\", label=\"Class 0\", alpha=0.6)\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color=\"blue\", label=\"Class 1\", alpha=0.6)\n",
    "plt.title(\"Dummy Binary Classification Data (for Logistic Regression)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "#implementing logistic regression\n",
    "#normalizing\n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "X = (X-mean)/std\n",
    "\n",
    "# Reshape y to be a column vector\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "# Initialize weights and bias\n",
    "w = np.array([[1.0],[1.5],[1.0],[0],[0]])\n",
    "b = 0\n",
    "all_cost = []\n",
    "\n",
    "m = X.shape[0]    # Number of training examples\n",
    "lr = 0.01   #learning rate\n",
    "\n",
    "# Create polynomial features: x1, x2, x1^2, x2^2, x1^3\n",
    "X1 = X[:,0] ** 2\n",
    "X2 = X[:,1] ** 2\n",
    "X3 = X[:,0] **3 \n",
    "\n",
    "# Concatenate original and polynomial features into design matrix\n",
    "x_train = np.concatenate([X[:,0],X[:,1],X1,X2,X3],axis=0)\n",
    "x_train = x_train.reshape(200,5)\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "x_train.shape\n",
    "\n",
    "# Training loop for logistic regression\n",
    "for _ in range(200):\n",
    " \n",
    "     y_ = sigmoid( x_train @ w + b)\n",
    "     j = (-1/m) * np.sum(y * np.log(y_) + (1 - y) * np.log(1-y_))   # Binary cross-entropy loss\n",
    "     all_cost.append(j)\n",
    "     # Gradient descent updates\n",
    "     w = w - lr * (1/m) * ((x_train.T) @ (y_- y))\n",
    "     b = b - lr * (1/m) * np.sum(y_ - y)\n",
    "print(j)\n",
    "# Plot decision boundary\n",
    "# Create a meshgrid over the feature space\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 300),\n",
    "    np.linspace(X[:, 1].min() - 1, X[:, 1].max() + 1, 300)\n",
    ")\n",
    "\n",
    "# Create the same polynomial features\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "grid_poly = np.hstack([\n",
    "    grid[:, 0].reshape(-1, 1),\n",
    "    grid[:, 1].reshape(-1, 1),\n",
    "    (grid[:, 0] ** 2).reshape(-1, 1),\n",
    "    (grid[:, 1] ** 2).reshape(-1, 1),\n",
    "    (grid[:, 0] ** 3).reshape(-1, 1)\n",
    "])\n",
    "\n",
    "# Predict on the grid\n",
    "z = sigmoid(grid_poly @ w + b)\n",
    "z = z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, z, levels=[0, 0.5, 1], alpha=0.2, colors=[\"red\", \"blue\"])\n",
    "plt.contour(xx, yy, z, levels=[0.5], linewidths=2, colors='black')\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y.flatten(), cmap='bwr', edgecolor='k')\n",
    "plt.title(\"Logistic Regression with Non-Linear Decision Boundary\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(all_cost)\n",
    "plt.show()\n",
    "add comments where required and check if any error"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
